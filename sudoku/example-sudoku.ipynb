{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptNet/qpth Example Sudoku Notebook\n",
    "\n",
    "*By [Brandon Amos](https://bamos.github.io) and [J. Zico Kolter](http://zicokolter.com/).*\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is released along with our paper\n",
    "[OptNet: Differentiable Optimization as a Layer in Neural Networks](https://arxiv.org/abs/1703.00443).\n",
    "\n",
    "This notebook shows an example of constructing an\n",
    "OptNet layer in PyTorch with our [qpth library](https://github.com/locuslab/qpth)\n",
    "to solve [the game Sudoku](https://en.wikipedia.org/wiki/Sudoku)\n",
    "as a prediction problem from data.\n",
    "See [our qpth documentation page](https://locuslab.github.io/qpth/)\n",
    "for more details on how to use `qpth`.\n",
    "The experiments for our paper that use this library are in\n",
    "[this repo](https://github.com/locuslab/optnet).\n",
    "Specifically [here](https://github.com/locuslab/optnet/tree/master/sudoku)\n",
    "is the full source code for the publihsed version of Sudoku.\n",
    "\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "+ Python/numpy/[PyTorch](https://pytorch.org)\n",
    "+ [qpth](https://github.com/locuslab/qpth):\n",
    "  *Our fast QP solver for PyTorch released in conjunction with this paper.*\n",
    "+ [bamos/block](https://github.com/bamos/block):\n",
    "  *Our intelligent block matrix library for numpy, PyTorch, and beyond.*\n",
    "+ Optional: [bamos/setGPU](https://github.com/bamos/setGPU):\n",
    "  A small library to set `CUDA_VISIBLE_DEVICES` on multi-GPU systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function, Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from qpth.qp import QPFunction\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: Download the data and pretrained model\n",
    "\n",
    "+ The pre-trained model is for later.\n",
    "  The following command should download everything to a tmp directory for you\n",
    "  if you have the `wget` and `tar` commands installed.\n",
    "+ (Sorry for the bad form here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmpDir = \"/tmp/optnet.sudoku\"\n",
    "# cmd = ('mkdir {}; cd {} &&'\n",
    "#        'wget \"http://joule.isr.cs.cmu.edu:11235/optnet/arxiv.v1.sudoku.tgz\" && '\n",
    "#        'tar xf arxiv.v1.sudoku.tgz').format(*[tmpDir]*2)\n",
    "# dataDir = os.path.join(tmpDir, 'arxiv.v1.sudoku')\n",
    "# assert os.system(cmd) == 0\n",
    "\n",
    "# sys.path.append(tmpDir+'/arxiv.v1.sudoku')\n",
    "# import models # From /tmp/optnet.sudoku/arxiv.v1.sudoku/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3447204/2347752599.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X = torch.load(f)\n",
      "/tmp/ipykernel_3447204/2347752599.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "testPct = 0.1\n",
    "dataDir = \"data\"\n",
    "with open('{}/2/features.pt'.format(dataDir), 'rb') as f:\n",
    "    X = torch.load(f)\n",
    "with open('{}/2/labels.pt'.format(dataDir), 'rb') as f:\n",
    "    Y = torch.load(f)\n",
    "\n",
    "N, nFeatures = X.size(0), int(np.prod(X.size()[1:]))\n",
    "\n",
    "nTrain = int(N*(1.-testPct))\n",
    "nTest = N-nTrain\n",
    "\n",
    "trainX = X[:nTrain]\n",
    "trainY = Y[:nTrain]\n",
    "testX = X[nTrain:]\n",
    "testY = Y[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What the data for the Sudoku task looks like\n",
    "\n",
    "The inputs are incomplete boards and the outputs\n",
    "are the completed boards. Here's what the first\n",
    "input and output in the test set looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First testing example input (unsolved Sudoku board):  tensor([[2, 0, 4, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 4, 0, 2],\n",
      "        [1, 0, 0, 0]])\n",
      "First testing example output (solved Sudoku board):  tensor([[2, 3, 4, 1],\n",
      "        [4, 1, 2, 3],\n",
      "        [3, 4, 1, 2],\n",
      "        [1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "def decode_onehot(encoded_board):\n",
    "    \"\"\"Take the unique argmax of the one-hot encoded board.\"\"\"\n",
    "    v,I = torch.max(encoded_board, 0)\n",
    "    return ((v>0).long()*(I+1)).squeeze()\n",
    "\n",
    "print(\"First testing example input (unsolved Sudoku board): \", decode_onehot(testX[0]))\n",
    "print(\"First testing example output (solved Sudoku board): \", decode_onehot(testY[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that we had to decode those examples.\n",
    "That's because they're actually *one-hot encoded* for how\n",
    "we're going to model the task.\n",
    "That means that instead of representing the values as \n",
    "something between 1 and 4, they're represented\n",
    "as a 4-dimensional vector with a 1 in the index of the value.\n",
    "Here's what the same first example from the test set\n",
    "actually looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First test example input one-hot encoded (unsolved Sudoku board):  tensor([[[0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "First test example output one-hot encoded (solved Sudoku board):  tensor([[[0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"First test example input one-hot encoded (unsolved Sudoku board): \", testX[0])\n",
    "print(\"First test example output one-hot encoded (solved Sudoku board): \", testY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a model for this task\n",
    "\n",
    "We've now turned (mini-)Sudoku into a machine learning task that\n",
    "you can apply any model and learning algorithm to. \n",
    "In this notebook, we'll just show how to initialize and train\n",
    "an OptNet model for this task.\n",
    "However you can play around and swap this out for any\n",
    "model you want!\n",
    "Check out [our baseline models](https://github.com/locuslab/optnet/blob/master/sudoku/models.py)\n",
    "if you're interested.\n",
    "\n",
    "Sudoku is actually an integer programming problem but\n",
    "we can relax it to an LP (or LP with a small ridge term,\n",
    "which we'll actually use) that can be expressed as:\n",
    "\n",
    "```\n",
    "y* = argmin_y 0.5 eps y^T y - p^T y\n",
    "         s.t. Ay  = b\n",
    "               y >= 0\n",
    "```\n",
    "\n",
    "To quickly explain this, the quadratic term `0.5 eps y^T y`\n",
    "is a small ridge term so we can use `qpth`,\n",
    "`p` is the (flattened) one-hot encoded input,\n",
    "the `-p^T y` term constrains the solution to contain\n",
    "the same pieces as the unsolved board,\n",
    "and the linear equality constraints `Ay = b`\n",
    "encode the constraints of Sudoku (the row, columns,\n",
    "and sub-blocks must contain all of the digits).\n",
    "\n",
    "If you want to check your understanding of this:\n",
    "\n",
    "1. What do some example constraints `a_i^T y = b_i` look like?\n",
    "2. What happens if we remove the linear equality constraint?\n",
    "\n",
    "Implementing this model is just a few lines of PyTorch with our qpth library.\n",
    "Note that in this notebook we'll just execute this on the CPU,\n",
    "but for performance reasons you should use a GPU for serious\n",
    "experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OptNet(nn.Module):\n",
    "    def __init__(self, n, Qpenalty):\n",
    "        super().__init__()\n",
    "        nx = (n**2)**3\n",
    "        # self.Q = Variable(Qpenalty*torch.eye(nx).double())\n",
    "        # self.G = Variable(-torch.eye(nx).double())\n",
    "        # self.h = Variable(torch.zeros(nx).double())\n",
    "        # A_shape = (40, 64) # Somewhat magic, it's from the true solution.\n",
    "        # self.A = Parameter(torch.rand(A_shape).double())\n",
    "        # self.b = Variable(torch.ones(A_shape[0]).double())\n",
    "        self.register_buffer('Q',  (Qpenalty * torch.eye(nx, dtype=torch.float64)))\n",
    "        self.register_buffer('G',  (-torch.eye(nx, dtype=torch.float64)))\n",
    "        self.register_buffer('h',  (torch.zeros(nx, dtype=torch.float64)))\n",
    "        self.A = nn.Parameter(torch.rand(40, 64, dtype=torch.float64))  # trainable\n",
    "        self.register_buffer('b',  (torch.ones(40, dtype=torch.float64)))\n",
    "\n",
    "    def forward(self, puzzles):\n",
    "        nBatch = puzzles.size(0)\n",
    "\n",
    "        p = -puzzles.view(nBatch, -1).double()  \n",
    "\n",
    "        return QPFunction(verbose=-1)(\n",
    "            self.Q, p.double(), self.G, self.h, self.A, self.b\n",
    "        ).float().view_as(puzzles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Let's randomly initialize this model and see what it does on the first test set example. What do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First test example input (unsolved Sudoku board):  tensor([[2, 0, 4, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 4, 0, 2],\n",
      "        [1, 0, 0, 0]])\n",
      "First test example output (TRUE solved Sudoku board):  tensor([[2, 3, 4, 1],\n",
      "        [4, 1, 2, 3],\n",
      "        [3, 4, 1, 2],\n",
      "        [1, 2, 3, 4]])\n",
      "First test example prediction:  tensor([[1, 2, 4, 3],\n",
      "        [2, 1, 4, 1],\n",
      "        [2, 4, 4, 2],\n",
      "        [2, 1, 1, 4]])\n"
     ]
    }
   ],
   "source": [
    "model = OptNet(2, 0.1) # n = 2, 4 * 4 puzzle; Q penalty = 0.1\n",
    "pred = model(Variable(testX[0].unsqueeze(0))).squeeze().data\n",
    "\n",
    "print(\"First test example input (unsolved Sudoku board): \", decode_onehot(testX[0]))\n",
    "print(\"First test example output (TRUE solved Sudoku board): \", decode_onehot(testY[0]))\n",
    "print(\"First test example prediction: \", decode_onehot(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow that prediction is way off!! That's expected since the model was randomly initialized. Note that at this point, some of the constraints actually make it impossible to match the unsolved board (like the `4` at the top right corner)\n",
    "\n",
    "Let's look a random nonsense constraint that the model just satisfied. Here are the coefficients in the first row, `a_1` and `b_1`. The last line here\n",
    "shows that the constraint is acutally satisfied (up to machine precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of A:\n",
      " [0.73 0.83 0.28 0.42 0.14 0.15 0.8  0.95 0.38 0.36 1.   0.75 0.69 0.33\n",
      " 0.66 0.05 0.27 0.75 0.38 0.66 0.6  0.24 0.7  0.62 0.89 0.36 0.8  0.78\n",
      " 0.04 0.14 0.21 0.3  0.03 0.12 0.71 0.37 0.78 0.14 0.89 0.3  0.65 0.93\n",
      " 0.1  0.32 0.25 0.02 0.1  0.13 0.55 0.18 0.24 0.33 0.87 0.2  0.44 0.14\n",
      " 0.11 0.92 0.58 0.12 0.38 0.98 0.52 0.23]\n",
      "------------------------------\n",
      "First entry of b:  tensor(1., dtype=torch.float64)\n",
      "------------------------------\n",
      "a0^T z - b:  tensor(7.0836e-09, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "a0 = model.A[0].data.numpy()\n",
    "b0 = model.b.data[0]\n",
    "z = pred.numpy().ravel()\n",
    "print('First row of A:\\n', a0)\n",
    "print('-'*30)\n",
    "print('First entry of b: ', b0)\n",
    "print('-'*30)\n",
    "print('a0^T z - b: ', np.dot(a0, z) - b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "Let's start training this model my comparing the predictions\n",
    "to the true solutions and taking gradient steps.\n",
    "This takes a while to run (overnight on a GPU), so here\n",
    "we'll just take 10 steps through the first 10 training examples\n",
    "to illustrate what the full training would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 0.24\n",
      "Epoch 1, loss = 0.24\n",
      "Epoch 2, loss = 0.24\n",
      "Epoch 3, loss = 0.24\n",
      "Epoch 4, loss = 0.24\n",
      "Epoch 5, loss = 0.23\n",
      "Epoch 6, loss = 0.23\n",
      "Epoch 7, loss = 0.23\n",
      "Epoch 8, loss = 0.23\n",
      "Epoch 9, loss = 0.23\n",
      "Epoch 10, loss = 0.23\n",
      "Epoch 11, loss = 0.23\n",
      "Epoch 12, loss = 0.23\n",
      "Epoch 13, loss = 0.23\n",
      "Epoch 14, loss = 0.23\n",
      "Epoch 15, loss = 0.23\n",
      "Epoch 16, loss = 0.22\n",
      "Epoch 17, loss = 0.22\n",
      "Epoch 18, loss = 0.22\n",
      "Epoch 19, loss = 0.22\n",
      "Epoch 20, loss = 0.22\n",
      "Epoch 21, loss = 0.22\n",
      "Epoch 22, loss = 0.22\n",
      "Epoch 23, loss = 0.22\n",
      "Epoch 24, loss = 0.22\n",
      "Epoch 25, loss = 0.22\n",
      "Epoch 26, loss = 0.22\n",
      "Epoch 27, loss = 0.21\n",
      "Epoch 28, loss = 0.21\n",
      "Epoch 29, loss = 0.21\n",
      "Epoch 30, loss = 0.21\n",
      "Epoch 31, loss = 0.21\n",
      "Epoch 32, loss = 0.21\n",
      "Epoch 33, loss = 0.21\n",
      "Epoch 34, loss = 0.20\n",
      "Epoch 35, loss = 0.20\n",
      "Epoch 36, loss = 0.20\n",
      "Epoch 37, loss = 0.20\n",
      "Epoch 38, loss = 0.19\n",
      "Epoch 39, loss = 0.19\n",
      "Epoch 40, loss = 0.18\n",
      "Epoch 41, loss = 0.18\n",
      "Epoch 42, loss = 0.17\n",
      "Epoch 43, loss = 0.16\n",
      "Epoch 44, loss = 0.15\n",
      "Epoch 45, loss = 0.15\n",
      "Epoch 46, loss = 0.14\n",
      "Epoch 47, loss = 0.14\n",
      "Epoch 48, loss = 0.13\n",
      "Epoch 49, loss = 0.12\n",
      "Epoch 50, loss = 0.11\n",
      "Epoch 51, loss = 0.10\n",
      "Epoch 52, loss = 0.10\n",
      "Epoch 53, loss = 0.10\n",
      "Epoch 54, loss = 0.09\n",
      "Epoch 55, loss = 0.08\n",
      "Epoch 56, loss = 0.08\n",
      "Epoch 57, loss = 0.07\n",
      "Epoch 58, loss = 0.07\n",
      "Epoch 59, loss = 0.07\n",
      "Epoch 60, loss = 0.06\n",
      "Epoch 61, loss = 0.06\n",
      "Epoch 62, loss = 0.05\n",
      "Epoch 63, loss = 0.05\n",
      "Epoch 64, loss = 0.05\n",
      "Epoch 65, loss = 0.04\n",
      "Epoch 66, loss = 0.04\n",
      "Epoch 67, loss = 0.04\n",
      "Epoch 68, loss = 0.04\n",
      "Epoch 69, loss = 0.03\n",
      "Epoch 70, loss = 0.03\n",
      "Epoch 71, loss = 0.03\n",
      "Epoch 72, loss = 0.03\n",
      "Epoch 73, loss = 0.02\n",
      "Epoch 74, loss = 0.02\n",
      "Epoch 75, loss = 0.02\n",
      "Epoch 76, loss = 0.02\n",
      "Epoch 77, loss = 0.02\n",
      "Epoch 78, loss = 0.02\n",
      "Epoch 79, loss = 0.02\n",
      "Epoch 80, loss = 0.01\n",
      "Epoch 81, loss = 0.01\n",
      "Epoch 82, loss = 0.01\n",
      "Epoch 83, loss = 0.01\n",
      "Epoch 84, loss = 0.01\n",
      "Epoch 85, loss = 0.01\n",
      "Epoch 86, loss = 0.01\n",
      "Epoch 87, loss = 0.01\n",
      "Epoch 88, loss = 0.01\n",
      "Epoch 89, loss = 0.01\n",
      "Epoch 90, loss = 0.01\n",
      "Epoch 91, loss = 0.01\n",
      "Epoch 92, loss = 0.01\n",
      "Epoch 93, loss = 0.01\n",
      "Epoch 94, loss = 0.01\n",
      "Epoch 95, loss = 0.00\n",
      "Epoch 96, loss = 0.00\n",
      "Epoch 97, loss = 0.00\n",
      "Epoch 98, loss = 0.00\n",
      "Epoch 99, loss = 0.00\n"
     ]
    }
   ],
   "source": [
    "model = OptNet(2, 0.1) # n = 2, 4 * 4 puzzle; Q penalty = 0.1\n",
    "model = model.cuda()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize the optimizer.\n",
    "learning_rate = 1e-1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    x_batch = trainX.cuda()\n",
    "    y_batch = trainY.cuda()\n",
    "    \n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x_batch)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    print('Epoch {}, loss = {:.2f}'.format(epoch, loss.item()))\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable weights\n",
    "    # of the model)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at a pre-trained model\n",
    "\n",
    "Imagine you kept that running for a while.\n",
    "Let's load my pre-trained model we downloaded earlier and\n",
    "see the predictions on the first test example again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First test example input (unsolved Sudoku board):  tensor([[2, 0, 4, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 4, 0, 2],\n",
      "        [1, 0, 0, 0]])\n",
      "First test example output (TRUE solved Sudoku board):  tensor([[2, 3, 4, 1],\n",
      "        [4, 1, 2, 3],\n",
      "        [3, 4, 1, 2],\n",
      "        [1, 2, 3, 4]])\n",
      "First test example prediction:  tensor([[2, 3, 4, 1],\n",
      "        [4, 1, 2, 3],\n",
      "        [3, 4, 1, 2],\n",
      "        [1, 2, 3, 4]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# A_file = os.path.join(tmpDir, 'arxiv.v1.sudoku', 'pretrained-optnet-A.pth')\n",
    "# trainedA = torch.load(A_file)\n",
    "\n",
    "# trainedModel = OptNet(2, 0.2)\n",
    "# trainedModel.A.data = trainedA\n",
    "\n",
    "# pred = trainedModel(Variable(testX[0].unsqueeze(0))).data.squeeze()\n",
    "pred = model(testX[0].unsqueeze(0).cuda()).data.squeeze()\n",
    "\n",
    "print(\"First test example input (unsolved Sudoku board): \", decode_onehot(testX[0]))\n",
    "print(\"First test example output (TRUE solved Sudoku board): \", decode_onehot(testY[0]))\n",
    "print(\"First test example prediction: \", decode_onehot(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it! With just a few lines of code we've trained\n",
    "an intuitive model that solves Sudoku.\n",
    "\n",
    "As a closing note, what does the trained `A` matrix look like?\n",
    "With this formulation, we don't expect it to be the nice,\n",
    "sparse coefficient matrix encoding the rules we typically\n",
    "think of Sudoku as since any row-transformed\n",
    "version of this matrix is an equivalent valid solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5033, -0.0236, -0.6012,  ..., -0.9560,  0.2507, -0.0707],\n",
       "        [ 0.4341,  0.3037, -0.5171,  ...,  0.2523, -1.2387, -0.7457],\n",
       "        [-0.6099, -0.2636,  1.4140,  ...,  0.3493,  0.7837,  0.4073],\n",
       "        ...,\n",
       "        [-0.4863, -0.0913,  0.8371,  ...,  0.6602, -0.5826,  0.5742],\n",
       "        [-0.3094, -1.2794,  0.3158,  ...,  1.3810,  0.4346,  0.0138],\n",
       "        [ 0.4512, -0.6674,  0.3066,  ..., -1.1187,  0.2641, -0.1476]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedA = model.A.data\n",
    "trainedA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilevel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
