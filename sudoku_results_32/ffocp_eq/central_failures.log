2025-09-29 00:49:17,719 - my_logger - INFO - 

2025-09-29 00:49:17,719 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 10:39:19,312 - my_logger - ERROR - ffocp_eq_n2_lr0.1_seed1: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 218, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 120, in train_test_loop
    loss.backward()
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 349, in backward
    sol_lagrangian[j].append(v.value[np.newaxis,:])
TypeError: 'NoneType' object is not subscriptable
2025-09-29 10:39:31,992 - my_logger - INFO - 

2025-09-29 10:39:31,993 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 11:44:39,673 - my_logger - INFO - 

2025-09-29 11:44:39,673 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 11:44:58,418 - my_logger - ERROR - ffocp_eq_n2_lr0.1_seed1: An error occurred: float() argument must be a string or a real number, not 'Equality'
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 218, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 120, in train_test_loop
    loss.backward()
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 378, in backward
    finite_difference_obj = objective + equality_dual_product + active_ineq_constraints
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/expressions/expression.py", line 50, in cast_op
    other = self.cast_to_const(other)
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/expressions/expression.py", line 588, in cast_to_const
    return expr if isinstance(expr, Expression) else cvxtypes.constant()(expr)
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/expressions/constants/constant.py", line 54, in __init__
    self._value = intf.DEFAULT_INTF.const_to_matrix(value)
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/interface/numpy_interface/ndarray_interface.py", line 56, in const_to_matrix
    return result.astype(numpy.float64)
TypeError: float() argument must be a string or a real number, not 'Equality'
2025-09-29 11:45:38,883 - my_logger - INFO - 

2025-09-29 11:45:38,883 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 11:45:51,690 - my_logger - ERROR - ffocp_eq_n2_lr0.1_seed1: An error occurred: float() argument must be a string or a real number, not 'Equality'
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 218, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 120, in train_test_loop
    loss.backward()
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 318, in backward
    active_ineq_constraints_dual_product = cp.sum([cp.sum(cp.multiply(dual, ineq)) for dual, ineq in zip(inequality_dual_params, active_ineq_constraints)])
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 318, in <listcomp>
    active_ineq_constraints_dual_product = cp.sum([cp.sum(cp.multiply(dual, ineq)) for dual, ineq in zip(inequality_dual_params, active_ineq_constraints)])
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/atoms/affine/binary_operators.py", line 243, in __init__
    lh_expr, rh_expr = self.broadcast(lh_expr, rh_expr)
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/expressions/expression.py", line 594, in broadcast
    rh_expr = Expression.cast_to_const(rh_expr)
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/expressions/expression.py", line 588, in cast_to_const
    return expr if isinstance(expr, Expression) else cvxtypes.constant()(expr)
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/expressions/constants/constant.py", line 54, in __init__
    self._value = intf.DEFAULT_INTF.const_to_matrix(value)
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/cvxpy/interface/numpy_interface/ndarray_interface.py", line 56, in const_to_matrix
    return result.astype(numpy.float64)
TypeError: float() argument must be a string or a real number, not 'Equality'
2025-09-29 11:46:28,455 - my_logger - INFO - 

2025-09-29 11:46:28,455 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 11:46:45,355 - my_logger - ERROR - ffocp_eq_n2_lr0.1_seed1: An error occurred: tuple index out of range
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 218, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 120, in train_test_loop
    loss.backward()
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 417, in backward
    new_val_i = _torch_exp(*vars_new_i, *params_i, *new_eq_dual_i, *new_ineq_dual_i)
  File "/nethome/zzhao628/cvxtorch/cvxtorch/torch_expression.py", line 266, in wrapped_func
    res.append(wrapped_func(self, curr_arg[0], rec_ind_to_value_type, vars_dict,
  File "/nethome/zzhao628/cvxtorch/cvxtorch/torch_expression.py", line 266, in wrapped_func
    res.append(wrapped_func(self, curr_arg[0], rec_ind_to_value_type, vars_dict,
  File "/nethome/zzhao628/cvxtorch/cvxtorch/torch_expression.py", line 266, in wrapped_func
    res.append(wrapped_func(self, curr_arg[0], rec_ind_to_value_type, vars_dict,
  File "/nethome/zzhao628/cvxtorch/cvxtorch/torch_expression.py", line 263, in wrapped_func
    res.append(args[vars_dict.vars_dict[curr_arg[0]]])
IndexError: tuple index out of range
2025-09-29 11:53:58,545 - my_logger - INFO - 

2025-09-29 11:53:58,545 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:08:29,483 - my_logger - INFO - 

2025-09-29 12:08:29,483 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:09:08,913 - my_logger - INFO - 

2025-09-29 12:09:08,913 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:09:54,228 - my_logger - INFO - 

2025-09-29 12:09:54,229 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:10:02,416 - my_logger - INFO - 

2025-09-29 12:10:02,416 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:19:23,897 - my_logger - INFO - 

2025-09-29 12:19:23,897 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:19:28,274 - my_logger - INFO - 

2025-09-29 12:19:28,274 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:21:07,063 - my_logger - INFO - 

2025-09-29 12:21:07,063 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:21:07,065 - my_logger - INFO - 

2025-09-29 12:21:07,065 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:21:23,088 - my_logger - ERROR - ffocp_eq_n2_lr0.1_seed1: An error occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 223, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 122, in train_test_loop
    loss.backward()
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 360, in backward
    if c.dual_value == None:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
2025-09-29 12:21:23,275 - my_logger - ERROR - ffocp_eq_n2_lr0.1_seed1: An error occurred: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 223, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 122, in train_test_loop
    loss.backward()
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 360, in backward
    if c.dual_value == None:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
2025-09-29 12:22:34,251 - my_logger - INFO - 

2025-09-29 12:22:34,251 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:22:34,288 - my_logger - INFO - 

2025-09-29 12:22:34,288 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:25:38,359 - my_logger - INFO - 

2025-09-29 12:25:38,359 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:25:39,677 - my_logger - ERROR - ffocp_eq_n2_lr0.01_seed1: An error occurred: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.22 GiB of which 12.69 MiB is free. Process 71726 has 73.76 GiB memory in use. Process 1835017 has 834.00 MiB memory in use. Process 1839852 has 834.00 MiB memory in use. Process 1840887 has 834.00 MiB memory in use. Process 1848438 has 834.00 MiB memory in use. Process 1851792 has 834.00 MiB memory in use. Process 1851875 has 834.00 MiB memory in use. Including non-PyTorch memory, this process has 520.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 223, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 36, in train_test_loop
    features = torch.tensor(features, dtype=torch.float32).to(device)[:]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.22 GiB of which 12.69 MiB is free. Process 71726 has 73.76 GiB memory in use. Process 1835017 has 834.00 MiB memory in use. Process 1839852 has 834.00 MiB memory in use. Process 1840887 has 834.00 MiB memory in use. Process 1848438 has 834.00 MiB memory in use. Process 1851792 has 834.00 MiB memory in use. Process 1851875 has 834.00 MiB memory in use. Including non-PyTorch memory, this process has 520.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-09-29 12:25:42,612 - my_logger - INFO - 

2025-09-29 12:25:42,612 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:25:43,478 - my_logger - ERROR - ffocp_eq_n2_lr0.001_seed1: An error occurred: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.22 GiB of which 12.69 MiB is free. Process 71726 has 73.76 GiB memory in use. Process 1835017 has 834.00 MiB memory in use. Process 1839852 has 834.00 MiB memory in use. Process 1840887 has 834.00 MiB memory in use. Process 1848438 has 834.00 MiB memory in use. Process 1851792 has 834.00 MiB memory in use. Process 1851875 has 834.00 MiB memory in use. Including non-PyTorch memory, this process has 520.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 223, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 36, in train_test_loop
    features = torch.tensor(features, dtype=torch.float32).to(device)[:]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.22 GiB of which 12.69 MiB is free. Process 71726 has 73.76 GiB memory in use. Process 1835017 has 834.00 MiB memory in use. Process 1839852 has 834.00 MiB memory in use. Process 1840887 has 834.00 MiB memory in use. Process 1848438 has 834.00 MiB memory in use. Process 1851792 has 834.00 MiB memory in use. Process 1851875 has 834.00 MiB memory in use. Including non-PyTorch memory, this process has 520.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-09-29 12:26:12,786 - my_logger - INFO - 

2025-09-29 12:26:12,787 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:26:14,862 - my_logger - INFO - 

2025-09-29 12:26:14,862 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:26:26,492 - my_logger - INFO - 

2025-09-29 12:26:26,492 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:26:28,758 - my_logger - INFO - 

2025-09-29 12:26:28,758 - my_logger - INFO - >>>>>>> START LOGGING <<<<<<<<
2025-09-29 12:35:12,765 - my_logger - ERROR - ffocp_eq_n2_lr0.1_seed1: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 223, in <module>
    train_test_loop(args, experiment_dir, n=n)
  File "/nethome/zzhao628/ffo-bilevel/sudoku/main_sudoku.py", line 122, in train_test_loop
    loss.backward()
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/nethome/zzhao628/anaconda3/envs/bilevel/lib/python3.10/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/nethome/zzhao628/ffo-bilevel/ffocp_eq.py", line 356, in backward
    sol_lagrangian[j].append(v.value[np.newaxis,:])
TypeError: 'NoneType' object is not subscriptable
